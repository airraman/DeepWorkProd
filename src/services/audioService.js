// src/services/audioService.js - Full Implementation with Background Music
import { Audio } from 'expo-av';
import { Platform } from 'react-native';

console.log('ðŸŽµ Loading audio service...');

/**
 * AudioService handles background music playback during deep work sessions
 * 
 * Key Responsibilities:
 * 1. Play looping background music (white noise, lo-fi)
 * 2. Pause/resume music when user pauses session
 * 3. Clean up audio resources to prevent memory leaks
 * 
 * INTERVIEW CONCEPT: Why a class instead of functions?
 * - We need to maintain STATE (current sound object, playing status)
 * - We need to ensure only ONE instance of audio plays at a time (Singleton pattern)
 * - Classes make it easier to manage the lifecycle of audio resources
 */
class AudioService {
  constructor() {
    // Track the currently playing sound object
    // CRITICAL: We must store this to stop/pause/resume later
    this.currentSound = null;
    
    // Track initialization state
    this.isInitialized = false;
    
    // Track what's currently playing
    this.currentMusicChoice = null;
    
    // Track playback state
    this.isPlaying = false;
    
    console.log('ðŸŽµ Audio service instance created');
  }

  /**
   * Initialize the audio system
   * 
   * INTERVIEW Q: Why do we need initialization?
   * A: Mobile audio systems require explicit configuration before use.
   *    We need to tell the OS how to handle our audio (background play,
   *    mixing with other apps, behavior when phone is on silent, etc.)
   * 
   * This is called ONCE when the app starts or when a session begins
   */
  async init() {
    try {
      console.log('ðŸŽµ Initializing audio service...');
      
      await Audio.setAudioModeAsync({
        playsInSilentModeIOS: true,
        staysActiveInBackground: true,
        
        // âœ… CRITICAL ADDITION #1: Proper category
        categoryIOS: Audio.AUDIO_SESSION_CATEGORY_PLAYBACK,
        
        // âœ… CRITICAL ADDITION #2: Category options
        categoryOptionsIOS: [
          Audio.CATEGORY_OPTIONS_MIXWITHOTHERS,
        ],
        
        // âœ… CRITICAL ADDITION #3: Interruption mode for background playback
        interruptionModeIOS: 2, // DO_NOT_MIX - won't pause when backgrounded
        
        // âœ… Allow Bluetooth
        allowsRecordingIOS: false,
        
        // Android equivalents
        interruptionModeAndroid: Audio.INTERRUPTION_MODE_ANDROID_DUCK_OTHERS,
        shouldDuckAndroid: true,
      });
      
      this.isInitialized = true;
      console.log('ðŸŽµ Audio service initialized successfully');
      return true;
      
    } catch (error) {
      console.error('ðŸŽµ Audio initialization error:', error);
      this.isInitialized = true;
      return false;
    }
  }

  /**
   * Play background music based on user's choice
   * 
   * @param {string} musicChoice - One of: 'none', 'white-noise', 'lofi'
   * 
   * FLOW:
   * 1. Stop any currently playing music
   * 2. If 'none' selected, just return
   * 3. Load the appropriate audio file
   * 4. Start playing with loop enabled
   * 
   * INTERVIEW Q: Why do we need to stop existing music first?
   * A: To prevent multiple audio streams playing simultaneously (memory leak + bad UX)
   */
  async playMusic(musicChoice) {
    try {
      console.log(`ðŸŽµ Request to play music: ${musicChoice}`);
      
      // If service isn't initialized, try to initialize now
      if (!this.isInitialized) {
        console.log('ðŸŽµ Service not initialized, initializing now...');
        await this.init();
      }
      
      // Stop any currently playing music first
      // CRITICAL: Prevents memory leaks from overlapping sounds
      await this.stopMusic();
      
      // If user selected 'no music', we're done
      if (musicChoice === 'none') {
        console.log('ðŸŽµ No music selected');
        return true;
      }
      
      // Map the user's choice to an actual audio file
      // INTERVIEW CONCEPT: Why use require() instead of a string path?
      // A: React Native bundles assets at compile time. require() tells the
      //    Metro bundler to include this file in the app bundle.
      let soundSource;
      switch (musicChoice) {
        case 'white-noise':
          // Note: File is called "white-noise.mp3" (with dash)
          soundSource = require('../../assets/sounds/white-noise.mp3');
          break;
        case 'lofi':
          soundSource = require('../../assets/sounds/lofi.mp3');
          break;
        default:
          console.warn(`ðŸŽµ Unknown music choice: ${musicChoice}`);
          return false;
      }
      
      console.log(`ðŸŽµ Loading audio for: ${musicChoice}`);
      
      /**
       * CRITICAL: Sound Loading
       * 
       * Audio.Sound.createAsync() does TWO things:
       * 1. Creates a Sound object
       * 2. Loads the audio data into memory
       * 
       * Returns: { sound, status }
       * - sound: The Sound object we'll use to control playback
       * - status: Current state (loaded, playing, duration, etc.)
       * 
       * INTERVIEW Q: Why destructure { sound }?
       * A: We only need the sound object, not the status
       */
      const { sound } = await Audio.Sound.createAsync(
        soundSource,
        {
          // Start playing immediately after loading
          shouldPlay: true,
          
          // Loop the music continuously
          // IMPORTANT: Background music should loop until session ends
          isLooping: true,
          
          // Set volume (0.0 to 1.0)
          // Using 0.5 so it's not overwhelming
          volume: 0.5,
        },
        // Status update callback (called when playback state changes)
        // We use this to track when playback finishes or errors occur
        this.onPlaybackStatusUpdate
      );
      
      // Store the sound object so we can control it later (pause/stop)
      // CRITICAL: Without this, we'd have no way to stop the music!
      this.currentSound = sound;
      this.currentMusicChoice = musicChoice;
      this.isPlaying = true;
      
      console.log(`ðŸŽµ Successfully playing: ${musicChoice}`);
      return true;
      
    } catch (error) {
      console.error('ðŸŽµ Error playing music:', error);
      
      // Clean up on error
      this.currentSound = null;
      this.currentMusicChoice = null;
      this.isPlaying = false;
      
      // Return false but don't crash the app
      // The session can continue without music
      return false;
    }
  }

  /**
   * Callback function that receives playback status updates
   * 
   * INTERVIEW CONCEPT: Callback Functions
   * - This is called automatically by expo-av when playback state changes
   * - Useful for tracking errors, completion, buffering, etc.
   * 
   * We use arrow function syntax (=>) so 'this' refers to our AudioService instance
   */
  onPlaybackStatusUpdate = (status) => {
    try {
      // If there was an error during playback
      if (status.error) {
        console.error('ðŸŽµ Playback error:', status.error);
        this.stopMusic(); // Clean up
      }
      
      // Track if sound has finished playing (shouldn't happen with looping)
      if (status.didJustFinish && !status.isLooping) {
        console.log('ðŸŽµ Playback finished');
        this.isPlaying = false;
      }
      
    } catch (error) {
      console.error('ðŸŽµ Status update error:', error);
    }
  };

  /**
   * Pause the currently playing music
   * 
   * INTERVIEW Q: What's the difference between pause and stop?
   * A: 
   * - Pause: Keeps audio loaded in memory, can resume from same position
   * - Stop: Unloads audio, resume would start from beginning
   * 
   * We use pause for session pauses (user might resume quickly)
   */
  async pauseMusic() {
    try {
      if (!this.currentSound) {
        console.log('ðŸŽµ No music to pause');
        return true;
      }
      
      console.log('ðŸŽµ Pausing music...');
      
      // Check if sound is actually playing before trying to pause
      const status = await this.currentSound.getStatusAsync();
      if (status.isPlaying) {
        await this.currentSound.pauseAsync();
        this.isPlaying = false;
        console.log('ðŸŽµ Music paused');
      }
      
      return true;
      
    } catch (error) {
      console.error('ðŸŽµ Error pausing music:', error);
      return false;
    }
  }

  /**
   * Resume playing music after pause
   * 
   * Continues from where it was paused
   */
  async resumeMusic() {
    try {
      if (!this.currentSound) {
        console.log('ðŸŽµ No music to resume');
        return true;
      }
      
      console.log('ðŸŽµ Resuming music...');
      
      // Check current status before resuming
      const status = await this.currentSound.getStatusAsync();
      if (!status.isPlaying && status.isLoaded) {
        await this.currentSound.playAsync();
        this.isPlaying = true;
        console.log('ðŸŽµ Music resumed');
      }
      
      return true;
      
    } catch (error) {
      console.error('ðŸŽµ Error resuming music:', error);
      return false;
    }
  }

  /**
   * Stop music and clean up resources
   * 
   * CRITICAL FUNCTION for preventing memory leaks
   * 
   * INTERVIEW CONCEPT: Resource Management
   * - Audio objects hold data in memory
   * - If we don't unload them, we get memory leaks
   * - Mobile devices have limited memory, so this is critical
   * 
   * Called when:
   * - User changes music selection
   * - Session ends
   * - Component unmounts
   */
  async stopMusic() {
    try {
      if (!this.currentSound) {
        console.log('ðŸŽµ No music to stop');
        return true;
      }
      
      console.log('ðŸŽµ Stopping music...');
      
      /**
       * IMPORTANT: Two-step cleanup process
       * 1. stopAsync() - Stop playback
       * 2. unloadAsync() - Free memory
       * 
       * INTERVIEW Q: Why two steps?
       * A: stopAsync() pauses playback but keeps data in memory (fast to resume)
       *    unloadAsync() removes data from memory (slow to restart, but frees resources)
       */
      await this.currentSound.stopAsync();
      await this.currentSound.unloadAsync();
      
      // Clear our references
      this.currentSound = null;
      this.currentMusicChoice = null;
      this.isPlaying = false;
      
      console.log('ðŸŽµ Music stopped and unloaded');
      return true;
      
    } catch (error) {
      console.error('ðŸŽµ Error stopping music:', error);
      
      // Even if there's an error, clear our references
      // This prevents us from trying to use a broken sound object
      this.currentSound = null;
      this.currentMusicChoice = null;
      this.isPlaying = false;
      
      return false;
    }
  }

  /**
   * Get current playback status
   * 
   * Useful for debugging or showing UI state
   */
  getStatus() {
    return {
      isInitialized: this.isInitialized,
      isPlaying: this.isPlaying,
      currentMusic: this.currentMusicChoice,
      hasSound: !!this.currentSound
    };
  }

  /**
   * Clean up all resources
   * 
   * Called when:
   * - App is closing
   * - Service is being reinitialized
   * - Component unmounts
   */
  async cleanup() {
    try {
      console.log('ðŸŽµ Cleaning up audio service...');
      await this.stopMusic();
      console.log('ðŸŽµ Audio service cleaned up successfully');
    } catch (error) {
      console.error('ðŸŽµ Cleanup error:', error);
    }
  }
}

/**
 * SINGLETON PATTERN
 * 
 * INTERVIEW CONCEPT: Why export a single instance instead of the class?
 * 
 * A: We want only ONE audio service in the entire app
 *    - Prevents multiple music streams playing simultaneously
 *    - Ensures consistent state across all components
 *    - Easier resource management
 * 
 * This is the Singleton pattern - commonly used for services like:
 * - Audio players
 * - Database connections
 * - API clients
 * - Logging services
 */
export const audioService = new AudioService();

console.log('ðŸŽµ Audio service exported successfully');